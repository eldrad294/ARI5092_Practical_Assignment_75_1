{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 1\n",
    "Procedure 1: 1) Fundamental data structures. 2) Tokenize / BOW. 3) Separate NB for each emotion class and Evaluation.\n",
    "\n",
    "Procedure 2 1) Test pairwise emotion labels (e1, e2) if prediction can be improved by adding a probability (pe1|e2). 2) Search through all possible pairwise label combinations to find highest probability + evaluation.\n",
    "\n",
    "Procedure 3 (MSC) 1) Evaluate performance for prediction of all emotion labels jointly. 2) Inference: Gibbs Sampling (or equivalent)\n",
    "\n",
    "## Procedure 1 - Corpus Cleaning + Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 lines of training corpus: \n",
      "[['tedcruz', 'handovertheserv', 'wipe', 'clean', 'k', 'delet', 'email', 'explain', 'derelict', 'dutyli', 'benghazi', 'etc', 'tcot'], ['hillari', 'best', 'choic', 'truli', 'want', 'continu', 'progress', 'nation', 'ohio'], ['theview', 'think', 'countri', 'readi', 'femal', 'pre', 'cant', 'ever', 'hillari'], ['gave', 'unhealthi', 'amount', 'hard-earn', 'money', 'away', 'big', 'govt', 'untrustworthi', 'ir', 'whyimnotvotingforhillari'], ['portiaaboulg', 'thank', 'ad', 'list']]\n",
      "\n",
      "First 5 lines of training labels: \n",
      "[['anger', 'anticipation', 'disgust', 'fear', '---', 'sadness', 'surprise', '---'], ['---', 'anticipation', '---', 'fear', 'joy', '---', '---', 'trust'], ['anger', 'anticipation', 'disgust', '---', 'joy', 'sadness', '---', '---'], ['anger', 'anticipation', 'disgust', 'fear', '---', 'sadness', '---', '---'], ['---', '---', '---', '---', 'joy', '---', '---', '---']]\n",
      "\n",
      "First 5 lines of testing labels: \n",
      "[['anger', 'anticipation', 'disgust', '---', 'joy', '---', '---', 'trust'], ['---', '---', '---', '---', 'joy', 'sadness', '---', 'trust'], ['---', 'anticipation', '---', '---', 'joy', '---', '---', 'trust'], ['---', 'anticipation', '---', 'fear', '---', 'sadness', '---', 'trust'], ['anger', 'anticipation', '---', 'fear', 'joy', '---', 'surprise', 'trust']]\n",
      "\n",
      "First 5 lines of testing binarized labels: \n",
      "[[1, 1, 1, 0, 1, 0, 0, 1], [0, 0, 0, 0, 1, 1, 0, 1], [0, 1, 0, 0, 1, 0, 0, 1], [0, 1, 0, 1, 0, 1, 0, 1], [1, 1, 0, 1, 1, 0, 1, 1]]\n",
      "\n",
      "Shape of training corpus: \n",
      "(2912,)\n",
      "Shape of training corpus: \n",
      "(2912, 8)\n",
      "Shape of testing corpus: \n",
      "(1956, 8)\n",
      "Shape of testing corpus: \n",
      "(1956, 8)\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import string\n",
    "#\n",
    "class Document:\n",
    "    \"\"\"\n",
    "    This class oversees reading, cleaning and formatting of the text corpus\n",
    "    \"\"\"\n",
    "    #\n",
    "    def __init__(self, path=None):\n",
    "        if path is not None:\n",
    "            BASE_DIR = os.path.join( os.path.dirname(os.getcwd()))\n",
    "            self.path = BASE_DIR + path\n",
    "        # Emotion Categories (Classes)\n",
    "        self.emotions = (\"anger\",\"anticipation\",\"disgust\",\"fear\",\"joy\",\"sadness\",\"surprise\",\"trust\")\n",
    "        self.stemmer = PorterStemmer()\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "    #\n",
    "    def __open_file_and_return_dump(self):\n",
    "        \"\"\" \n",
    "        Opens file and returns a dump containing all the data.\n",
    "        The data structure used to record the dumped data is a list of strings,\n",
    "        where each string represents a single record).\n",
    "        \"\"\"\n",
    "        corpus = []\n",
    "        with open(self.path) as csvfile:\n",
    "            rows = csv.reader(csvfile)\n",
    "            for row in rows:\n",
    "                temp_string = \"\"\n",
    "                for item in row:\n",
    "                    temp_string += str(item) + \" \"\n",
    "                corpus.append(temp_string)\n",
    "        return corpus\n",
    "    #\n",
    "    def __split_labels_from_vectors(self):\n",
    "        \"\"\"\n",
    "        Takes corpus as input, and splits the data into respective labels and training data.\n",
    "        Returns this data as two separate lists\n",
    "        \"\"\"\n",
    "        #\n",
    "        corpus = self.__open_file_and_return_dump()\n",
    "        label_count = len(self.emotions)\n",
    "        character_splitter = '\\t'\n",
    "        train_y, train_X = [], []\n",
    "        for row in corpus:\n",
    "            groups = row.split(character_splitter)\n",
    "            train_y.append(character_splitter.join(groups[:label_count]))\n",
    "            train_X.append(character_splitter.join(groups[label_count:]))\n",
    "        return train_y, train_X\n",
    "    #\n",
    "    def __tokenize_corpus(self, data, delimeter=\" \"):\n",
    "        \"\"\"\n",
    "        Takes a list as input, and tokenizes the data.\n",
    "        \"\"\"\n",
    "        corpus = []\n",
    "        [(corpus.append(row.split(delimeter))) for row in data]\n",
    "        return corpus\n",
    "    #\n",
    "    def __replace(self, word, symbols, placeholder=\"\"):\n",
    "        \"\"\"\n",
    "        An overriding of the original python method, so as to replace all characters \n",
    "        in a string based on whether they occur in a list.\n",
    "        \"\"\"\n",
    "        temp_string = word\n",
    "        for symbol in symbols:\n",
    "            temp_string = temp_string.replace(symbol, placeholder)\n",
    "        return temp_string\n",
    "    #\n",
    "    def __remove_stop_words(self, data):\n",
    "        \"\"\"\n",
    "        Takes a list of data, and iterates over each element to \n",
    "        scan and remove stop words.\n",
    "\n",
    "        The method ensures to convert all text instances to lowercase.\n",
    "\n",
    "        The method ensures to remove jargon symbols (#,%,&,etc).\n",
    "\n",
    "        This method ensures to remove punctuation.\n",
    "        \"\"\"\n",
    "        temp_list, jargon_symbols = [], ('%','$','#','@','^','&','*','(',')','+','/','\\'','!','?','.',',',':',';','~','0','1','2','3','4','5','6','7','8','9')\n",
    "        for row in data:\n",
    "            filtered_words = [self.__replace(word.lower().translate(string.punctuation), symbols=jargon_symbols) for word in row if word.lower() not in stopwords.words('english')]          \n",
    "            temp_list.append(filtered_words)\n",
    "        #\n",
    "        new_list = []\n",
    "        for row in temp_list:\n",
    "            row_list = []\n",
    "            for word in row:\n",
    "                if word != \"\":\n",
    "                    row_list.append(word)\n",
    "            new_list.append(row_list)\n",
    "        #\n",
    "        return new_list\n",
    "    #\n",
    "    def __word_morhpology(self, data, stemming=0, lemmatizing=0):\n",
    "        temp_list = []\n",
    "        for row in data:\n",
    "            filtered_words = row\n",
    "            if stemming == 1:\n",
    "                # Stemming\n",
    "                filtered_words = [self.stemmer.stem(word) for word in filtered_words]\n",
    "            #\n",
    "            if stemming == 1:\n",
    "                # Lemmatizing\n",
    "                filtered_words = [self.lemmatizer.lemmatize(word) for word in filtered_words]\n",
    "            #\n",
    "            temp_list.append(filtered_words)\n",
    "        #\n",
    "        return temp_list\n",
    "    #\n",
    "    def get_emotions(self):\n",
    "        return self.emotions\n",
    "    #\n",
    "    def clean_corpus(self):\n",
    "        train_y, train_X = self.__split_labels_from_vectors()\n",
    "        tokenized_X, tokenized_y = self.__tokenize_corpus(data=train_X), self.__tokenize_corpus(data=train_y, delimeter=\"\\t\")\n",
    "        cleaned_tokenized_X, cleaned_tokenized_y = self.__remove_stop_words(data=tokenized_X), self.__remove_stop_words(data=tokenized_y)\n",
    "        cleaned_tokenized_X = self.__word_morhpology(cleaned_tokenized_X,1,1)\n",
    "        return cleaned_tokenized_X, cleaned_tokenized_y\n",
    "    #\n",
    "    def binarize(self, y):\n",
    "        value = \"---\"\n",
    "        y_binarized = []\n",
    "        for i in range(len(y)):\n",
    "            y_binarized.append([])\n",
    "            for element in y[i]:\n",
    "                if value in element:\n",
    "                    y_binarized[i].append(0)\n",
    "                else:\n",
    "                    y_binarized[i].append(1)\n",
    "        return y_binarized\n",
    "#\n",
    "training_document = Document(path=\"\\\\data\\\\ssec-aggregated\\\\train-combined-0.0.csv\")\n",
    "cleaned_tokenized_train_X, cleaned_tokenized_train_y = training_document.clean_corpus()\n",
    "#\n",
    "# This will be used later for evaluation purposes\n",
    "testing_document = Document(path= \"\\\\data\\\\ssec-aggregated\\\\test-combined-0.0.csv\")\n",
    "cleaned_tokenized_test_X, cleaned_tokenized_test_y = testing_document.clean_corpus()\n",
    "binarized_cleaned_tokenized_test_y = testing_document.binarize(cleaned_tokenized_test_y)\n",
    "#\n",
    "print(\"First 5 lines of training corpus: \\n\" + str(cleaned_tokenized_train_X[0:5]) + \"\\n\")\n",
    "print(\"First 5 lines of training labels: \\n\" + str(cleaned_tokenized_train_y[0:5]) + \"\\n\")\n",
    "print(\"First 5 lines of testing labels: \\n\" + str(cleaned_tokenized_test_y[0:5]) + \"\\n\")\n",
    "print(\"First 5 lines of testing binarized labels: \\n\" + str(binarized_cleaned_tokenized_test_y[0:5]) + \"\\n\")\n",
    "print(\"Shape of training corpus: \\n\" + str(np.shape(cleaned_tokenized_train_X)))\n",
    "print(\"Shape of training corpus: \\n\" + str(np.shape(cleaned_tokenized_train_y)))\n",
    "print(\"Shape of testing corpus: \\n\" + str(np.shape(cleaned_tokenized_test_y)))\n",
    "print(\"Shape of testing corpus: \\n\" + str(np.shape(binarized_cleaned_tokenized_test_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procedure 1 - Naive Bayes Class Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anger: 1\n",
      "Anticipation: 1\n",
      "Disgust: 1\n",
      "Fear: 0\n",
      "Joy: 1\n",
      "Sadness: 0\n",
      "Surprise: 0\n",
      "Trust: 0\n"
     ]
    }
   ],
   "source": [
    "class NaiveBayes:\n",
    "    \"\"\"\n",
    "    This class oversees the Naive Bayes Model Template\n",
    "    \"\"\"\n",
    "    #\n",
    "    def __init__(self, emotion_index):\n",
    "        \"\"\"\n",
    "        Constructor\n",
    "        \"\"\"\n",
    "        d = Document()\n",
    "        self.emotions = d.get_emotions()\n",
    "        self.emotion_index = emotion_index\n",
    "        if self.emotion_index > len(self.emotions):\n",
    "            print(\"Index exceeds the current emotion list capacity. Index musn't exceed \" + str(len(self.emotions)))\n",
    "        self.BOW_0, self.BOW_1 = {}, {} # Separate BOW models (BOW_1 - For likely vocab, BOW_0 - For not likely vocab)\n",
    "        self.word_count_category_0, self.word_count_category_1 = 0,0 \n",
    "    #\n",
    "    def __get_sentiment(self):\n",
    "        \"\"\"\n",
    "        Returns emotion of this instance classifier\n",
    "        \"\"\"\n",
    "        return self.emotions[self.emotion_index]\n",
    "    #\n",
    "    def __prod(self,iterable):\n",
    "        \"\"\"\n",
    "        Product multiplier - Accepts list and returns product of all list elements\n",
    "        \"\"\"\n",
    "        product = 1\n",
    "        for number in iterable:\n",
    "            product *= number\n",
    "        return product\n",
    "    #\n",
    "    def __calculate_NB(self, liklihood_prob, prior_prob):\n",
    "        return self.__prod(liklihood_prob) * prior_prob\n",
    "    #\n",
    "    def __calculate_pairwise_NB(self, e1_liklihood_prob, e2_liklihood_prob, e1_prior_prob, e2_prior_prob, pairwise_prob):\n",
    "        return pairwise_prob * e1_prior_prob * e2_prior_prob * self.__prod(e1_liklihood_prob) * self.__prod(e2_liklihood_prob)\n",
    "    #\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Accepts training data and training labels, which will form the basis of the Naive Bayes model.\n",
    "        This function oversees cosntruction of the bag of words model. \n",
    "        \"\"\"\n",
    "        selected_emotion = self.__get_sentiment()\n",
    "        #\n",
    "        for i in range(len(y)):\n",
    "            if selected_emotion in y[i]:\n",
    "                for word in X[i]:\n",
    "                    self.word_count_category_1 += 1\n",
    "                    if word in self.BOW_1:\n",
    "                        self.BOW_1[word] += 1\n",
    "                    else:\n",
    "                        self.BOW_1[word] = 1\n",
    "            else:\n",
    "                for word in X[i]:\n",
    "                    self.word_count_category_0 += 1\n",
    "                    if word in self.BOW_0:\n",
    "                        self.BOW_0[word] += 1\n",
    "                    else:\n",
    "                        self.BOW_0[word] = 1\n",
    "    #\n",
    "    def predict_proba(self, X, pairwise_emotion=None):\n",
    "        \"\"\"\n",
    "        Accepts input document, and returns estimated liklihoods for an emotion holding and not holding.\n",
    "        \n",
    "        The method also accepts a second parameter, denoting a pairwise emotion. If the parameter is not empty,\n",
    "        the liklihood emotions of holding/not holding will be calculated based on P(e1|e2).\n",
    "        \n",
    "        X                :text document (sentence to be classified)\n",
    "        pairwise_emotion :Emotion 2 pairwise model\n",
    "        \n",
    "        \"\"\"\n",
    "        prob_0, prob_1 = 0,0\n",
    "        #\n",
    "        # Calculating Prior Probabilities for initial emotion\n",
    "        e1_prior_prob = sum(self.BOW_1.values()) / (sum(self.BOW_0.values()) + sum(self.BOW_1.values())) \n",
    "        e1_prior_prob_na = sum(self.BOW_0.values()) / (sum(self.BOW_0.values()) + sum(self.BOW_1.values()))\n",
    "        if pairwise_emotion is not None:\n",
    "            #\n",
    "            # Calculating Prior Probabilities for pairwise emotion\n",
    "            e2_BOW_0, e2_BOW_1 = pairwise_emotion.get_model_BOWs()\n",
    "            e2_prior_prob = sum(e2_BOW_1.values()) / (sum(e2_BOW_0.values()) + sum(e2_BOW_1.values())) \n",
    "            e2_prior_prob_na = sum(e2_BOW_0.values()) / (sum(e2_BOW_0.values()) + sum(e2_BOW_1.values()))\n",
    "            #\n",
    "            # Calculating probability of e1 given e2\n",
    "            e1_count, e2_count = 0,0\n",
    "            for emotions in cleaned_tokenized_train_y:\n",
    "                if pairwise_emotion.__get_sentiment() in emotions:\n",
    "                    e2_count += 1\n",
    "                    if self.__get_sentiment() in emotions:\n",
    "                        e1_count += 1\n",
    "            pairwise_prob = e1_count / e2_count\n",
    "        #\n",
    "        # Calculating the liklihood probability of having this emotion\n",
    "        e1_likelihood_probabilities, e2_likelihood_probabilities = [], []\n",
    "        for word in X:\n",
    "            if word in self.BOW_1:\n",
    "                e1_likelihood_probability = self.BOW_1[word] / e1_prior_prob\n",
    "                e1_likelihood_probabilities.append(e1_likelihood_probability)\n",
    "            if pairwise_emotion is not None and word in e2_BOW_1:\n",
    "                e2_likelihood_probability = e2_BOW_1[word] / e2_prior_prob\n",
    "                e2_likelihood_probabilities.append(e2_likelihood_probability)\n",
    "        #\n",
    "        if pairwise_emotion is not None:\n",
    "            prob_1 = self.__calculate_pairwise_NB(e1_liklihood_prob=e1_likelihood_probabilities, \n",
    "                                                  e2_liklihood_prob=e2_likelihood_probabilities, \n",
    "                                                  e1_prior_prob=e1_prior_prob, \n",
    "                                                  e2_prior_prob=e2_prior_prob,\n",
    "                                                  pairwise_prob=pairwise_prob)\n",
    "        else:\n",
    "            prob_1 = self.__calculate_NB(e1_likelihood_probabilities, e1_prior_prob)\n",
    "        #\n",
    "        # Calculating the liklihood probability of not having this emotion\n",
    "        e1_likelihood_probabilities, e2_likelihood_probabilities = [], []\n",
    "        for word in X:\n",
    "            if word in self.BOW_0:\n",
    "                e1_likelihood_probability = self.BOW_0[word] / e1_prior_prob_na\n",
    "                e1_likelihood_probabilities.append(e1_likelihood_probability)\n",
    "            if pairwise_emotion is not None and word in e2_BOW_0:\n",
    "                e2_likelihood_probability = e2_BOW_0[word] / e2_prior_prob_na\n",
    "                e2_likelihood_probabilities.append(e2_likelihood_probability)\n",
    "        #\n",
    "        if pairwise_emotion is not None:\n",
    "            prob_0 = self.__calculate_pairwise_NB(e1_liklihood_prob=e1_likelihood_probabilities, \n",
    "                                                  e2_liklihood_prob=e2_likelihood_probabilities, \n",
    "                                                  e1_prior_prob=e1_prior_prob, \n",
    "                                                  e2_prior_prob=e2_prior_prob,\n",
    "                                                  pairwise_prob=pairwise_prob)\n",
    "        else:     \n",
    "            prob_0 = self.__calculate_NB(e1_likelihood_probabilities, e1_prior_prob_na)\n",
    "            \n",
    "        #\n",
    "        return prob_0, prob_1\n",
    "    #\n",
    "    def predict(self, X, pairwise_emotion=None):\n",
    "        \"\"\"\n",
    "        A wrapper function for: \n",
    "        \n",
    "        self.predict_proba\n",
    "        \n",
    "        Returns whether emotion holds or not\n",
    "        \"\"\"\n",
    "        prob_0, prob_1 = self.predict_proba(X,pairwise_emotion)\n",
    "        if prob_0 > prob_1:\n",
    "            return 0 # Emotion is not likely\n",
    "        else:\n",
    "            return 1 # Emotion is likely\n",
    "    #\n",
    "    def get_model_BOWs(self):\n",
    "        return self.BOW_0, self.BOW_1\n",
    "        \n",
    "#\n",
    "NB_classifier_anger = NaiveBayes(0)\n",
    "NB_classifier_anger.fit(X=cleaned_tokenized_train_X, y=cleaned_tokenized_train_y)\n",
    "NB_classifier_anticipation = NaiveBayes(1)\n",
    "NB_classifier_anticipation.fit(X=cleaned_tokenized_train_X, y=cleaned_tokenized_train_y)\n",
    "NB_classifier_disgust = NaiveBayes(2)\n",
    "NB_classifier_disgust.fit(X=cleaned_tokenized_train_X, y=cleaned_tokenized_train_y)\n",
    "NB_classifier_fear = NaiveBayes(3)\n",
    "NB_classifier_fear.fit(X=cleaned_tokenized_train_X, y=cleaned_tokenized_train_y)\n",
    "NB_classifier_joy = NaiveBayes(4)\n",
    "NB_classifier_joy.fit(X=cleaned_tokenized_train_X, y=cleaned_tokenized_train_y)\n",
    "NB_classifier_sadness = NaiveBayes(5)\n",
    "NB_classifier_sadness.fit(X=cleaned_tokenized_train_X, y=cleaned_tokenized_train_y)\n",
    "NB_classifier_surprise = NaiveBayes(6)\n",
    "NB_classifier_surprise.fit(X=cleaned_tokenized_train_X, y=cleaned_tokenized_train_y)\n",
    "NB_classifier_trust = NaiveBayes(7)\n",
    "NB_classifier_trust.fit(X=cleaned_tokenized_train_X, y=cleaned_tokenized_train_y)\n",
    "#\n",
    "classifiers = [NB_classifier_anger, \n",
    "               NB_classifier_anticipation, \n",
    "               NB_classifier_disgust, \n",
    "               NB_classifier_fear, \n",
    "               NB_classifier_joy, \n",
    "               NB_classifier_sadness, \n",
    "               NB_classifier_surprise, \n",
    "               NB_classifier_trust]\n",
    "#\n",
    "# Quick Testing\n",
    "test = \"If you want to live as a healer\".split()\n",
    "pred = NB_classifier_anger.predict(test)\n",
    "print(\"Anger: \" + str(pred))\n",
    "pred = NB_classifier_anticipation.predict(test)\n",
    "print(\"Anticipation: \" + str(pred))\n",
    "pred = NB_classifier_disgust.predict(test)\n",
    "print(\"Disgust: \" + str(pred))\n",
    "pred = NB_classifier_fear.predict(test)\n",
    "print(\"Fear: \" + str(pred))\n",
    "pred = NB_classifier_joy.predict(test)\n",
    "print(\"Joy: \" + str(pred))\n",
    "pred = NB_classifier_sadness.predict(test)\n",
    "print(\"Sadness: \" + str(pred))\n",
    "pred = NB_classifier_surprise.predict(test)\n",
    "print(\"Surprise: \" + str(pred))\n",
    "pred = NB_classifier_trust.predict(test)\n",
    "print(\"Trust: \" + str(pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procedure 1 - Individual emotion model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anger Accuracy: 70.3987730061\n",
      "Anger Precision: 75.1510574018\n",
      "Anger Recall: 79.9196787149\n",
      "Anger F-Score: 77.4620474893\n",
      "------------------------------------------------\n",
      "Anticipation Accuracy: 59.6625766871\n",
      "Anticipation Precision: 68.0555555556\n",
      "Anticipation Recall: 65.0622406639\n",
      "Anticipation F-Score: 66.5252439542\n",
      "------------------------------------------------\n",
      "Disgust Accuracy: 64.8261758691\n",
      "Disgust Precision: 61.0671936759\n",
      "Disgust Recall: 67.7631578947\n",
      "Disgust F-Score: 64.2411642412\n",
      "------------------------------------------------\n",
      "Fear Accuracy: 62.5766871166\n",
      "Fear Precision: 54.4854881266\n",
      "Fear Recall: 51.625\n",
      "Fear F-Score: 53.0166880616\n",
      "------------------------------------------------\n",
      "Joy Accuracy: 64.3149284254\n",
      "Joy Precision: 53.5499398315\n",
      "Joy Recall: 58.784676354\n",
      "Joy F-Score: 56.0453400504\n",
      "------------------------------------------------\n",
      "Sadness Accuracy: 60.6850715746\n",
      "Sadness Precision: 62.3728813559\n",
      "Sadness Recall: 69.3685202639\n",
      "Sadness F-Score: 65.6849620705\n",
      "------------------------------------------------\n",
      "Surprise Accuracy: 64.9795501022\n",
      "Surprise Precision: 32.9004329004\n",
      "Surprise Recall: 28.8425047438\n",
      "Surprise F-Score: 30.7381193124\n",
      "------------------------------------------------\n",
      "Trust Accuracy: 68.7627811861\n",
      "Trust Precision: 55.7565789474\n",
      "Trust Recall: 49.7797356828\n",
      "Trust F-Score: 52.5989138867\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def true_label_alloc(binarized_cleaned_tokenized_test_y, index):\n",
    "    \"\"\"\n",
    "    Iterates through all correct labels and retrieves only that\n",
    "    subset which corresponds to the desired emotion.\n",
    "    \"\"\"\n",
    "    y_true = []\n",
    "    for row in binarized_cleaned_tokenized_test_y:\n",
    "        y_true.append(row[index])\n",
    "    return y_true\n",
    "#\n",
    "# Anger Model Evaluation\n",
    "y_true, y_pred = true_label_alloc(binarized_cleaned_tokenized_test_y,0), []\n",
    "for sentence in cleaned_tokenized_test_X:\n",
    "    predictions = NB_classifier_anger.predict(sentence)\n",
    "    y_pred.append(predictions)\n",
    "print(\"Anger Accuracy: \" + str(accuracy_score(y_true, y_pred) * 100))\n",
    "print(\"Anger Precision: \" + str(precision_score(y_true, y_pred) * 100))\n",
    "print(\"Anger Recall: \" + str(recall_score(y_true, y_pred) * 100))\n",
    "print(\"Anger F-Score: \" + str(f1_score(y_true, y_pred) * 100))\n",
    "print(\"------------------------------------------------\")\n",
    "#\n",
    "# Anticipation Model Evaluation\n",
    "y_true, y_pred = true_label_alloc(binarized_cleaned_tokenized_test_y,1), []\n",
    "for sentence in cleaned_tokenized_test_X:\n",
    "    predictions = NB_classifier_anticipation.predict(sentence)\n",
    "    y_pred.append(predictions)\n",
    "print(\"Anticipation Accuracy: \" + str(accuracy_score(y_true, y_pred) * 100))\n",
    "print(\"Anticipation Precision: \" + str(precision_score(y_true, y_pred) * 100))\n",
    "print(\"Anticipation Recall: \" + str(recall_score(y_true, y_pred) * 100))\n",
    "print(\"Anticipation F-Score: \" + str(f1_score(y_true, y_pred) * 100))\n",
    "print(\"------------------------------------------------\")\n",
    "#\n",
    "# Disgust Model Evaluation\n",
    "y_true, y_pred = true_label_alloc(binarized_cleaned_tokenized_test_y,2), []\n",
    "for sentence in cleaned_tokenized_test_X:\n",
    "    predictions = NB_classifier_disgust.predict(sentence)\n",
    "    y_pred.append(predictions)\n",
    "print(\"Disgust Accuracy: \" + str(accuracy_score(y_true, y_pred) * 100))\n",
    "print(\"Disgust Precision: \" + str(precision_score(y_true, y_pred) * 100))\n",
    "print(\"Disgust Recall: \" + str(recall_score(y_true, y_pred) * 100))\n",
    "print(\"Disgust F-Score: \" + str(f1_score(y_true, y_pred) * 100))\n",
    "print(\"------------------------------------------------\")\n",
    "#\n",
    "# Fear Model Evaluation\n",
    "y_true, y_pred = true_label_alloc(binarized_cleaned_tokenized_test_y,3), []\n",
    "for sentence in cleaned_tokenized_test_X:\n",
    "    predictions = NB_classifier_fear.predict(sentence)\n",
    "    y_pred.append(predictions)\n",
    "print(\"Fear Accuracy: \" + str(accuracy_score(y_true, y_pred) * 100))\n",
    "print(\"Fear Precision: \" + str(precision_score(y_true, y_pred) * 100))\n",
    "print(\"Fear Recall: \" + str(recall_score(y_true, y_pred) * 100))\n",
    "print(\"Fear F-Score: \" + str(f1_score(y_true, y_pred) * 100))\n",
    "print(\"------------------------------------------------\")\n",
    "#\n",
    "# Joy Model Evaluation\n",
    "y_true, y_pred = true_label_alloc(binarized_cleaned_tokenized_test_y,4), []\n",
    "for sentence in cleaned_tokenized_test_X:\n",
    "    predictions = NB_classifier_joy.predict(sentence)\n",
    "    y_pred.append(predictions)\n",
    "print(\"Joy Accuracy: \" + str(accuracy_score(y_true, y_pred) * 100))\n",
    "print(\"Joy Precision: \" + str(precision_score(y_true, y_pred) * 100))\n",
    "print(\"Joy Recall: \" + str(recall_score(y_true, y_pred) * 100))\n",
    "print(\"Joy F-Score: \" + str(f1_score(y_true, y_pred) * 100))\n",
    "print(\"------------------------------------------------\")\n",
    "#\n",
    "# Sadness Model Evaluation\n",
    "y_true, y_pred = true_label_alloc(binarized_cleaned_tokenized_test_y,5), []\n",
    "for sentence in cleaned_tokenized_test_X:\n",
    "    predictions = NB_classifier_sadness.predict(sentence)\n",
    "    y_pred.append(predictions)\n",
    "print(\"Sadness Accuracy: \" + str(accuracy_score(y_true, y_pred) * 100))\n",
    "print(\"Sadness Precision: \" + str(precision_score(y_true, y_pred) * 100))\n",
    "print(\"Sadness Recall: \" + str(recall_score(y_true, y_pred) * 100))\n",
    "print(\"Sadness F-Score: \" + str(f1_score(y_true, y_pred) * 100))\n",
    "print(\"------------------------------------------------\")\n",
    "#\n",
    "# Surprise Model Evaluation\n",
    "y_true, y_pred = true_label_alloc(binarized_cleaned_tokenized_test_y,6), []\n",
    "for sentence in cleaned_tokenized_test_X:\n",
    "    predictions = NB_classifier_surprise.predict(sentence)\n",
    "    y_pred.append(predictions)\n",
    "print(\"Surprise Accuracy: \" + str(accuracy_score(y_true, y_pred) * 100))\n",
    "print(\"Surprise Precision: \" + str(precision_score(y_true, y_pred) * 100))\n",
    "print(\"Surprise Recall: \" + str(recall_score(y_true, y_pred) * 100))\n",
    "print(\"Surprise F-Score: \" + str(f1_score(y_true, y_pred) * 100))\n",
    "print(\"------------------------------------------------\")\n",
    "#\n",
    "# Trust Model Evaluation\n",
    "y_true, y_pred = true_label_alloc(binarized_cleaned_tokenized_test_y,7), []\n",
    "for sentence in cleaned_tokenized_test_X:\n",
    "    predictions = NB_classifier_trust.predict(sentence)\n",
    "    y_pred.append(predictions)\n",
    "print(\"Trust Accuracy: \" + str(accuracy_score(y_true, y_pred) * 100))\n",
    "print(\"Trust Precision: \" + str(precision_score(y_true, y_pred) * 100))\n",
    "print(\"Trust Recall: \" + str(recall_score(y_true, y_pred) * 100))\n",
    "print(\"Trust F-Score: \" + str(f1_score(y_true, y_pred) * 100))\n",
    "print(\"------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procedure 1 - Collective emotion model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 64.5258179959\n",
      "Precision: 61.171011328\n",
      "Recall: 62.3539232053\n",
      "F-Score: 61.7568033069\n"
     ]
    }
   ],
   "source": [
    "y_true, y_pred = binarized_cleaned_tokenized_test_y, []\n",
    "for sentence in cleaned_tokenized_test_X:\n",
    "    predictions = [NB_classifier_anger.predict(sentence),\n",
    "                   NB_classifier_anticipation.predict(sentence),\n",
    "                   NB_classifier_disgust.predict(sentence),\n",
    "                   NB_classifier_fear.predict(sentence),\n",
    "                   NB_classifier_joy.predict(sentence),\n",
    "                   NB_classifier_sadness.predict(sentence),\n",
    "                   NB_classifier_surprise.predict(sentence),\n",
    "                   NB_classifier_trust.predict(sentence)]\n",
    "    y_pred.append(predictions)\n",
    "#\n",
    "def flatten(iterable):\n",
    "    flattened_list = []\n",
    "    for row in iterable:\n",
    "        for element in row:\n",
    "            flattened_list.append(element)\n",
    "    return flattened_list\n",
    "y_true = flatten(y_true)\n",
    "y_pred = flatten(y_pred)\n",
    "#\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_true, y_pred) * 100))\n",
    "print(\"Precision: \" + str(precision_score(y_true, y_pred) * 100))\n",
    "print(\"Recall: \" + str(recall_score(y_true, y_pred) * 100))\n",
    "print(\"F-Score: \" + str(f1_score(y_true, y_pred) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procedure 2 - Pairwise emotion evaluation (Disgust|Anger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disgust|Anger Accuracy: 65.3374233129\n",
      "Disgust|Anger Precision: 59.8319327731\n",
      "Disgust|Anger Recall: 78.0701754386\n",
      "Disgust|Anger F-Score: 67.7450047574\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Disgust|Anger Model Evaluation\n",
    "y_true, y_pred = true_label_alloc(binarized_cleaned_tokenized_test_y,2), []\n",
    "for sentence in cleaned_tokenized_test_X:\n",
    "    predictions = NB_classifier_disgust.predict(sentence,NB_classifier_anger)\n",
    "    y_pred.append(predictions)\n",
    "print(\"Disgust|Anger Accuracy: \" + str(accuracy_score(y_true, y_pred) * 100))\n",
    "print(\"Disgust|Anger Precision: \" + str(precision_score(y_true, y_pred) * 100))\n",
    "print(\"Disgust|Anger Recall: \" + str(recall_score(y_true, y_pred) * 100))\n",
    "print(\"Disgust|Anger F-Score: \" + str(f1_score(y_true, y_pred) * 100))\n",
    "print(\"------------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
