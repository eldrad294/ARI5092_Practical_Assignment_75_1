{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "\n",
    "* Implement a linear chain CRF with a library\n",
    "* Use it on two data sets with the same set of features\n",
    "* Implement the model and evaluate with F-Score. How are the feature weights which are learnt different between the models?\n",
    "\n",
    "## File handling and data loading\n",
    "\n",
    "Loads data from files, for both POS training&testing and NER training&testing files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Notebook Imports\n",
    "\"\"\"\n",
    "import os\n",
    "import pycrfsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example: [['Measuring', 'NN'], ['cups', 'NNS'], ['may', 'MD'], ['soon', 'RB'], ['be', 'VB']]\n"
     ]
    }
   ],
   "source": [
    "class DataLoader:\n",
    "    \"\"\"\n",
    "    Loads input data files and cleans up data into following format:\n",
    "    \n",
    "    eg: (Data1, Type1)\n",
    "    \"\"\"\n",
    "    #\n",
    "    def __init__(self, POS_train_path, POS_test_path, NER_train_path, NER_test_path):\n",
    "        \"\"\"\n",
    "        Loads data files into memory\n",
    "        \"\"\"\n",
    "        __POS_train_path = POS_train_path\n",
    "        __POS_test_path = POS_test_path\n",
    "        __NER_train_path = NER_train_path\n",
    "        __NER_test_path = NER_test_path\n",
    "        #\n",
    "        # Loads data from disk into memory\n",
    "        __POS_train_data, __POS_test_data, __NER_train_data, __NER_test_data = self.__extract_data_from_files(POS_train_path=__POS_train_path,\n",
    "                                                                                                              POS_test_path=__POS_test_path,\n",
    "                                                                                                              NER_train_path=__NER_train_path,\n",
    "                                                                                                              NER_test_path=__NER_test_path)\n",
    "        #\n",
    "        # Formats data currently loaded in memory into a formatted structure\n",
    "        self.__POS_train_structured_data, self.__POS_test_structured_data, self.__NER_train_structured_data,self.__NER_test_structured_data=self.__format_data(POS_train_data=__POS_train_data,\n",
    "                                                                                                                                                               POS_test_data=__POS_test_data,\n",
    "                                                                                                                                                               NER_train_data=__NER_train_data,\n",
    "                                                                                                                                                               NER_test_data=__NER_test_data)\n",
    "    #\n",
    "    def __extract_data_from_files(self, POS_train_path, POS_test_path, NER_train_path, NER_test_path):\n",
    "        \"\"\"\n",
    "        Opens data files and returns data in memory\n",
    "        \"\"\"\n",
    "        #\n",
    "        BASE_DIR = os.path.join( os.path.dirname(os.getcwd()))\n",
    "        #\n",
    "        with open(BASE_DIR + POS_train_path) as f:\n",
    "            POS_train_data = f.read()\n",
    "        with open(BASE_DIR + POS_test_path) as f:\n",
    "            POS_test_data = f.read()\n",
    "        with open(BASE_DIR + NER_train_path) as f:\n",
    "            NER_train_data = f.read()\n",
    "        with open(BASE_DIR + NER_test_path) as f:\n",
    "            NER_test_data = f.read()\n",
    "        #\n",
    "        return POS_train_data, POS_test_data, NER_train_data, NER_test_data\n",
    "    #\n",
    "    def __format_data(self, POS_train_data, POS_test_data, NER_train_data, NER_test_data):\n",
    "        \"\"\"\n",
    "        Formats data into a python data structure (list of lists)\n",
    "        eg: (Data1, Type1)\n",
    "        \"\"\"\n",
    "        POS_train_structured_data, POS_test_structured_data, NER_train_structured_data, NER_test_structured_data = [],[],[],[]\n",
    "        for line in POS_train_data.split(\"\\n\"):\n",
    "            #print(line)\n",
    "            if line is not None and line != \"\": \n",
    "                sub_list = line.split(\"\\t\")\n",
    "                POS_train_structured_data.append(sub_list)\n",
    "        for line in POS_test_data.split(\"\\n\"):\n",
    "            if line is not None and line != \"\": \n",
    "                sub_list = line.split(\"\\t\")\n",
    "                POS_test_structured_data.append(sub_list)\n",
    "        for line in NER_train_data.split(\"\\n\"):\n",
    "            if line is not None and line != \"\": \n",
    "                sub_list = line.split(\"\\t|\")\n",
    "                NER_train_structured_data.append(sub_list)\n",
    "        for line in NER_test_data.split(\"\\n\"):\n",
    "            if line is not None and line != \"\": \n",
    "                sub_list = line.split(\"\\t|\")\n",
    "                NER_test_structured_data.append(sub_list)\n",
    "        #\n",
    "        return POS_train_structured_data, POS_test_structured_data, NER_train_structured_data, NER_test_structured_data\n",
    "    #\n",
    "    def load_data(self):\n",
    "        \"\"\"\n",
    "        Method wrapper which loads data into memory and returns all relevant training and testing files\n",
    "        \"\"\"\n",
    "        return self.__POS_train_structured_data, self.__POS_test_structured_data, self.__NER_train_structured_data, self.__NER_test_structured_data\n",
    "#\n",
    "data_loader_obj = DataLoader(POS_train_path=\"\\\\data\\\\pos\\\\train.col\",\n",
    "                             POS_test_path=\"\\\\data\\\\pos\\\\test.col\",\n",
    "                             NER_train_path=\"\\\\data\\\\ner-pol\\\\train.iob\",\n",
    "                             NER_test_path=\"\\\\data\\\\ner-pol\\\\test.iob\")\n",
    "POS_train_data, POS_test_data, NER_train_data, NER_test_data = data_loader_obj.load_data()\n",
    "print(\"Example: \" + str(POS_test_data[0:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Enhancer\n",
    "\n",
    "Adds more features to the already loaded vectors, including the following features:\n",
    "\n",
    "* The word itself, coverted to lower case\n",
    "* Word Suffix (-2,-3)\n",
    "* Boolean if string is uppercased\n",
    "* Boolean if string is a title (eg: Title)\n",
    "* Boolean if string is a digit\n",
    "* The postag\n",
    "* The string before it, converted to lowercase\n",
    "* Boolean if the string before it is a title (eg: Title)\n",
    "* Boolean if the string before it is uppercased\n",
    "* Boolean if the string before it is a digit\n",
    "* postag of string before it\n",
    "* The string after it, converted to lowercase\n",
    "* Boolean if the string after it is a title (eg: Title)\n",
    "* Boolean if the string after it is uppercased\n",
    "* Boolean if the string after it is a digit\n",
    "* postag of string after it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X POS Train Vector: \n",
      "[['bias', 'word.lower=in', 'word[-3:]=In', 'word[-2:]=In', 'word.isupper=False', 'word.istitle=True', 'word.isdigit=False', 'postag=IN', 'BOS', '+1:word.lower=an', '+1:word.istitle=False', '+1:word.isupper=False', '+1:word.isdigit=False', '+1:postag=DT'], ['bias', 'word.lower=an', 'word[-3:]=an', 'word[-2:]=an', 'word.isupper=False', 'word.istitle=False', 'word.isdigit=False', 'postag=DT', '-1:word.lower=in', '-1:word.istitle=True', '-1:word.isupper=False', '-1:word.isdigit=False', '-1:postag=IN', '+1:word.lower=oct.', '+1:word.istitle=True', '+1:word.isupper=False', '+1:word.isdigit=False', '+1:postag=NNP'], ['bias', 'word.lower=oct.', 'word[-3:]=ct.', 'word[-2:]=t.', 'word.isupper=False', 'word.istitle=True', 'word.isdigit=False', 'postag=NNP', '-1:word.lower=an', '-1:word.istitle=False', '-1:word.isupper=False', '-1:word.isdigit=False', '-1:postag=DT', '+1:word.lower=19', '+1:word.istitle=False', '+1:word.isupper=False', '+1:word.isdigit=True', '+1:postag=CD'], ['bias', 'word.lower=19', 'word[-3:]=19', 'word[-2:]=19', 'word.isupper=False', 'word.istitle=False', 'word.isdigit=True', 'postag=CD', '-1:word.lower=oct.', '-1:word.istitle=True', '-1:word.isupper=False', '-1:word.isdigit=False', '-1:postag=NNP', '+1:word.lower=review', '+1:word.istitle=False', '+1:word.isupper=False', '+1:word.isdigit=False', '+1:postag=NN'], ['bias', 'word.lower=review', 'word[-3:]=iew', 'word[-2:]=ew', 'word.isupper=False', 'word.istitle=False', 'word.isdigit=False', 'postag=NN', '-1:word.lower=19', '-1:word.istitle=False', '-1:word.isupper=False', '-1:word.isdigit=True', '-1:postag=CD', '+1:word.lower=of', '+1:word.istitle=False', '+1:word.isupper=False', '+1:word.isdigit=False', '+1:postag=IN']]\n",
      "\n",
      "y POS Train Labels: \n",
      "['IN', 'DT', 'NNP', 'CD', 'NN']\n",
      "\n",
      "X POS Test Vector: \n",
      "[['bias', 'word.lower=measuring', 'word[-3:]=ing', 'word[-2:]=ng', 'word.isupper=False', 'word.istitle=True', 'word.isdigit=False', 'postag=NN', 'BOS', '+1:word.lower=cups', '+1:word.istitle=False', '+1:word.isupper=False', '+1:word.isdigit=False', '+1:postag=NNS'], ['bias', 'word.lower=cups', 'word[-3:]=ups', 'word[-2:]=ps', 'word.isupper=False', 'word.istitle=False', 'word.isdigit=False', 'postag=NNS', '-1:word.lower=measuring', '-1:word.istitle=True', '-1:word.isupper=False', '-1:word.isdigit=False', '-1:postag=NN', '+1:word.lower=may', '+1:word.istitle=False', '+1:word.isupper=False', '+1:word.isdigit=False', '+1:postag=MD'], ['bias', 'word.lower=may', 'word[-3:]=may', 'word[-2:]=ay', 'word.isupper=False', 'word.istitle=False', 'word.isdigit=False', 'postag=MD', '-1:word.lower=cups', '-1:word.istitle=False', '-1:word.isupper=False', '-1:word.isdigit=False', '-1:postag=NNS', '+1:word.lower=soon', '+1:word.istitle=False', '+1:word.isupper=False', '+1:word.isdigit=False', '+1:postag=RB'], ['bias', 'word.lower=soon', 'word[-3:]=oon', 'word[-2:]=on', 'word.isupper=False', 'word.istitle=False', 'word.isdigit=False', 'postag=RB', '-1:word.lower=may', '-1:word.istitle=False', '-1:word.isupper=False', '-1:word.isdigit=False', '-1:postag=MD', '+1:word.lower=be', '+1:word.istitle=False', '+1:word.isupper=False', '+1:word.isdigit=False', '+1:postag=VB'], ['bias', 'word.lower=be', 'word[-3:]=be', 'word[-2:]=be', 'word.isupper=False', 'word.istitle=False', 'word.isdigit=False', 'postag=VB', '-1:word.lower=soon', '-1:word.istitle=False', '-1:word.isupper=False', '-1:word.isdigit=False', '-1:postag=RB', '+1:word.lower=replaced', '+1:word.istitle=False', '+1:word.isupper=False', '+1:word.isdigit=False', '+1:postag=VBN']]\n",
      "\n",
      "y POS Test Labels: \n",
      "['NN', 'NNS', 'MD', 'RB', 'VB']\n",
      "\n",
      "X NER Train Vector: \n",
      "[['bias', 'word.lower=-docstart-', 'word[-3:]=RT-', 'word[-2:]=T-', 'word.isupper=True', 'word.istitle=False', 'word.isdigit=False', 'postag=O', 'BOS', '+1:word.lower=eu', '+1:word.istitle=False', '+1:word.isupper=True', '+1:word.isdigit=False', '+1:postag=B-ORG'], ['bias', 'word.lower=eu', 'word[-3:]=EU', 'word[-2:]=EU', 'word.isupper=True', 'word.istitle=False', 'word.isdigit=False', 'postag=B-ORG', '-1:word.lower=-docstart-', '-1:word.istitle=False', '-1:word.isupper=True', '-1:word.isdigit=False', '-1:postag=O', '+1:word.lower=rejects', '+1:word.istitle=False', '+1:word.isupper=False', '+1:word.isdigit=False', '+1:postag=O'], ['bias', 'word.lower=rejects', 'word[-3:]=cts', 'word[-2:]=ts', 'word.isupper=False', 'word.istitle=False', 'word.isdigit=False', 'postag=O', '-1:word.lower=eu', '-1:word.istitle=False', '-1:word.isupper=True', '-1:word.isdigit=False', '-1:postag=B-ORG', '+1:word.lower=german', '+1:word.istitle=True', '+1:word.isupper=False', '+1:word.isdigit=False', '+1:postag=B-MISC'], ['bias', 'word.lower=german', 'word[-3:]=man', 'word[-2:]=an', 'word.isupper=False', 'word.istitle=True', 'word.isdigit=False', 'postag=B-MISC', '-1:word.lower=rejects', '-1:word.istitle=False', '-1:word.isupper=False', '-1:word.isdigit=False', '-1:postag=O', '+1:word.lower=call', '+1:word.istitle=False', '+1:word.isupper=False', '+1:word.isdigit=False', '+1:postag=O'], ['bias', 'word.lower=call', 'word[-3:]=all', 'word[-2:]=ll', 'word.isupper=False', 'word.istitle=False', 'word.isdigit=False', 'postag=O', '-1:word.lower=german', '-1:word.istitle=True', '-1:word.isupper=False', '-1:word.isdigit=False', '-1:postag=B-MISC', '+1:word.lower=to', '+1:word.istitle=False', '+1:word.isupper=False', '+1:word.isdigit=False', '+1:postag=O']]\n",
      "\n",
      "y NER Train Labels: \n",
      "['O', 'B-ORG', 'O', 'B-MISC', 'O']\n",
      "\n",
      "X NER Test Vector: \n",
      "[['bias', 'word.lower=-docstart-', 'word[-3:]=RT-', 'word[-2:]=T-', 'word.isupper=True', 'word.istitle=False', 'word.isdigit=False', 'postag=O', 'BOS', '+1:word.lower=soccer', '+1:word.istitle=False', '+1:word.isupper=True', '+1:word.isdigit=False', '+1:postag=O'], ['bias', 'word.lower=soccer', 'word[-3:]=CER', 'word[-2:]=ER', 'word.isupper=True', 'word.istitle=False', 'word.isdigit=False', 'postag=O', '-1:word.lower=-docstart-', '-1:word.istitle=False', '-1:word.isupper=True', '-1:word.isdigit=False', '-1:postag=O', '+1:word.lower=-', '+1:word.istitle=False', '+1:word.isupper=False', '+1:word.isdigit=False', '+1:postag=O'], ['bias', 'word.lower=-', 'word[-3:]=-', 'word[-2:]=-', 'word.isupper=False', 'word.istitle=False', 'word.isdigit=False', 'postag=O', '-1:word.lower=soccer', '-1:word.istitle=False', '-1:word.isupper=True', '-1:word.isdigit=False', '-1:postag=O', '+1:word.lower=japan', '+1:word.istitle=False', '+1:word.isupper=True', '+1:word.isdigit=False', '+1:postag=B-LOC'], ['bias', 'word.lower=japan', 'word[-3:]=PAN', 'word[-2:]=AN', 'word.isupper=True', 'word.istitle=False', 'word.isdigit=False', 'postag=B-LOC', '-1:word.lower=-', '-1:word.istitle=False', '-1:word.isupper=False', '-1:word.isdigit=False', '-1:postag=O', '+1:word.lower=get', '+1:word.istitle=False', '+1:word.isupper=True', '+1:word.isdigit=False', '+1:postag=O'], ['bias', 'word.lower=get', 'word[-3:]=GET', 'word[-2:]=ET', 'word.isupper=True', 'word.istitle=False', 'word.isdigit=False', 'postag=O', '-1:word.lower=japan', '-1:word.istitle=False', '-1:word.isupper=True', '-1:word.isdigit=False', '-1:postag=B-LOC', '+1:word.lower=lucky', '+1:word.istitle=False', '+1:word.isupper=True', '+1:word.isdigit=False', '+1:postag=O']]\n",
      "\n",
      "y NER Test Labels: \n",
      "['O', 'O', 'O', 'B-LOC', 'O']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def word2features(doc, i, model_type):\n",
    "    \"\"\"\n",
    "    Accepts a word, and respective POS tag, and converts it into a vector of features\n",
    "    \n",
    "    Applies different features to the model, depending on whether we are tackling POS tagging, or NER tagging.\n",
    "    \"\"\"\n",
    "    #print(doc[i])\n",
    "    word = doc[i][0]\n",
    "    postag = doc[i][1]\n",
    "    #\n",
    "    if model_type == 0: # POS Tagging Features\n",
    "        #\n",
    "        features = [\n",
    "            'bias',\n",
    "            'word.lower=' + word.lower(),\n",
    "            'word[-3:]=' + word[-3:],\n",
    "            'word[-2:]=' + word[-2:],\n",
    "            'word.isupper=%s' % word.isupper(),\n",
    "            'word.istitle=%s' % word.istitle(),\n",
    "            'word.isdigit=%s' % word.isdigit(),\n",
    "            'postag=' + postag\n",
    "        ]\n",
    "        #\n",
    "        # Preword\n",
    "        if i > 0:\n",
    "            word1 = doc[i-1][0]\n",
    "            postag1 = doc[i-1][1]\n",
    "            features.extend([\n",
    "                '-1:word.lower=' + word1.lower(),\n",
    "                '-1:word.istitle=%s' % word1.istitle(),\n",
    "                '-1:word.isupper=%s' % word1.isupper(),\n",
    "                '-1:word.isdigit=%s' % word1.isdigit(),\n",
    "                '-1:postag=' + postag1\n",
    "            ])\n",
    "        else:\n",
    "            # Beginning of document\n",
    "            features.append('BOS')\n",
    "        #\n",
    "        # Postword\n",
    "        if i < len(doc)-1:\n",
    "            word1 = doc[i+1][0]\n",
    "            postag1 = doc[i+1][1]\n",
    "            features.extend([\n",
    "                '+1:word.lower=' + word1.lower(),\n",
    "                '+1:word.istitle=%s' % word1.istitle(),\n",
    "                '+1:word.isupper=%s' % word1.isupper(),\n",
    "                '+1:word.isdigit=%s' % word1.isdigit(),\n",
    "                '+1:postag=' + postag1\n",
    "            ])\n",
    "        else:\n",
    "            # End of document\n",
    "            features.append('EOS')\n",
    "    else:\n",
    "        #\n",
    "        features = [\n",
    "            'bias',\n",
    "            'word.lower=' + word.lower(),\n",
    "            'word[-3:]=' + word[-3:],\n",
    "            'word[-2:]=' + word[-2:],\n",
    "            'word.isupper=%s' % word.isupper(),\n",
    "            'word.istitle=%s' % word.istitle(),\n",
    "            'word.isdigit=%s' % word.isdigit(),\n",
    "            'postag=' + postag\n",
    "        ]\n",
    "        #\n",
    "        # Preword\n",
    "        if i > 0:\n",
    "            word1 = doc[i-1][0]\n",
    "            postag1 = doc[i-1][1]\n",
    "            features.extend([\n",
    "                '-1:word.lower=' + word1.lower(),\n",
    "                '-1:word.istitle=%s' % word1.istitle(),\n",
    "                '-1:word.isupper=%s' % word1.isupper(),\n",
    "                '-1:word.isdigit=%s' % word1.isdigit(),\n",
    "                '-1:postag=' + postag1\n",
    "            ])\n",
    "        else:\n",
    "            # Beginning of document\n",
    "            features.append('BOS')\n",
    "        #\n",
    "        # Postword\n",
    "        if i < len(doc)-1:\n",
    "            word1 = doc[i+1][0]\n",
    "            postag1 = doc[i+1][1]\n",
    "            features.extend([\n",
    "                '+1:word.lower=' + word1.lower(),\n",
    "                '+1:word.istitle=%s' % word1.istitle(),\n",
    "                '+1:word.isupper=%s' % word1.isupper(),\n",
    "                '+1:word.isdigit=%s' % word1.isdigit(),\n",
    "                '+1:postag=' + postag1\n",
    "            ])\n",
    "        else:\n",
    "            # End of document\n",
    "            features.append('EOS')\n",
    "    #    \n",
    "    return features\n",
    "#\n",
    "# Function for extracting features & labels\n",
    "def extract_features_labels(data, model_type):\n",
    "    \"\"\"\n",
    "    Accepts 2 params:\n",
    "    \n",
    "    1) data: upon which to split into training vectors (X) and labels (y)\n",
    "    2) model_type: upon which to apply specific features\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(len(data)):\n",
    "        X.append(word2features(doc=data, i=i, model_type=model_type))\n",
    "        y.append(data[i][1])\n",
    "    return X,y\n",
    "\n",
    "X_POS_train_data, y_POS_train_data = extract_features_labels(data=POS_train_data, model_type=0)\n",
    "X_POS_test_data,  y_POS_test_data  = extract_features_labels(data=POS_test_data,  model_type=0)\n",
    "X_NER_train_data, y_NER_train_data = extract_features_labels(data=NER_train_data, model_type=1)\n",
    "X_NER_test_data,  y_NER_test_data  = extract_features_labels(data=NER_test_data,  model_type=1)\n",
    "# #\n",
    "# # A function for extracting features in documents\n",
    "# def extract_features(doc, model_type):\n",
    "#     \"\"\"\n",
    "#     Accepts 2 params:\n",
    "    \n",
    "#     1) data: upon which to split into training vectors (X) and labels (y)\n",
    "#     2) model_type: upon which to apply specific features\n",
    "#     \"\"\"\n",
    "#     return [word2features(doc, i, model_type) for i in range(len(doc))]\n",
    "# #\n",
    "# # A function fo generating the list of labels for each document\n",
    "# def get_labels(doc):\n",
    "#     return [label for (token, postag, label) in doc]\n",
    "# #\n",
    "# # Model POS\n",
    "# X_POS_train_data = [extract_features(doc, model_type=0) for doc in POS_train_data]\n",
    "# y_POS_train_data = [get_labels(doc) for doc in POS_train_data]\n",
    "# X_POS_test_data = [extract_features(doc, model_type=0) for doc in POS_test_data]\n",
    "# y_POS_test_data = [get_labels(doc) for doc in POS_test_data]\n",
    "# #\n",
    "# # Model NER\n",
    "# X_NER_train_data = [extract_features(doc, model_type=1) for doc in NER_train_data]\n",
    "# y_NER_train_data = [get_labels(doc) for doc in NER_train_data]\n",
    "# X_NER_test_data = [extract_features(doc, model_type=1) for doc in NER_test_data]\n",
    "# y_NER_test_data = [get_labels(doc) for doc in NER_test_data]\n",
    "#\n",
    "print(\"X POS Train Vector: \\n\" + str(X_POS_train_data[0:5]) + \"\\n\")\n",
    "print(\"y POS Train Labels: \\n\" + str(y_POS_train_data[0:5]) + \"\\n\")\n",
    "print(\"X POS Test Vector: \\n\" + str(X_POS_test_data[0:5]) + \"\\n\")\n",
    "print(\"y POS Test Labels: \\n\" + str(y_POS_test_data[0:5]) + \"\\n\")\n",
    "print(\"X NER Train Vector: \\n\" + str(X_NER_train_data[0:5]) + \"\\n\")\n",
    "print(\"y NER Train Labels: \\n\" + str(y_NER_train_data[0:5]) + \"\\n\")\n",
    "print(\"X NER Test Vector: \\n\" + str(X_NER_test_data[0:5]) + \"\\n\")\n",
    "print(\"y NER Test Labels: \\n\" + str(y_NER_test_data[0:5]) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model - POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature generation\n",
      "type: CRF1d\n",
      "feature.minfreq: 0.000000\n",
      "feature.possible_states: 0\n",
      "feature.possible_transitions: 1\n",
      "0....1....2....3....4"
     ]
    }
   ],
   "source": [
    "trainer_POS = pycrfsuite.Trainer(verbose=True)\n",
    "#\n",
    "# Submit training data to the trainer\n",
    "for xseq, yseq in zip(X_POS_train_data, y_POS_train_data):\n",
    "    #print(xseq)\n",
    "    #print(yseq)\n",
    "    trainer_POS.append([xseq], [yseq])\n",
    "# print(len(X_POS_train_data))\n",
    "# print(len(y_POS_train_data))\n",
    "# trainer_POS.append(X_POS_train_data, y_POS_train_data)\n",
    "#\n",
    "# Set the parameters of the model\n",
    "trainer_POS.set_params({\n",
    "    # coefficient for L1 penalty\n",
    "    'c1': 0.1,\n",
    "\n",
    "    # coefficient for L2 penalty\n",
    "    'c2': 0.01,  \n",
    "\n",
    "    # maximum number of iterations\n",
    "    'max_iterations': 100,\n",
    "\n",
    "    # whether to include transitions that\n",
    "    # are possible, but not observed\n",
    "    'feature.possible_transitions': True\n",
    "})\n",
    "#\n",
    "# Provide a file name as a parameter to the train function, such that\n",
    "# the model will be saved to the file when training is finished\n",
    "trainer_POS.train('POS_crf.model')\n",
    "print('POS Model Trained..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model - NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_NER = pycrfsuite.Trainer(verbose=True)\n",
    "#\n",
    "# Submit training data to the trainer\n",
    "for xseq, yseq in zip(X_NER_train_data, y_NER_train_data):\n",
    "    #print(xseq)\n",
    "    #print(yseq)\n",
    "    trainer_NER.append([xseq], [yseq])\n",
    "# print(len(X_POS_train_data))\n",
    "# print(len(y_POS_train_data))\n",
    "# trainer_POS.append(X_POS_train_data, y_POS_train_data)\n",
    "#\n",
    "# Set the parameters of the model\n",
    "trainer_NER.set_params({\n",
    "    # coefficient for L1 penalty\n",
    "    'c1': 0.1,\n",
    "\n",
    "    # coefficient for L2 penalty\n",
    "    'c2': 0.01,  \n",
    "\n",
    "    # maximum number of iterations\n",
    "    'max_iterations': 100,\n",
    "\n",
    "    # whether to include transitions that\n",
    "    # are possible, but not observed\n",
    "    'feature.possible_transitions': True\n",
    "})\n",
    "#\n",
    "# Provide a file name as a parameter to the train function, such that\n",
    "# the model will be saved to the file when training is finished\n",
    "trainer_NER.train('NER_crf.model')\n",
    "print('NER Model Trained..')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
