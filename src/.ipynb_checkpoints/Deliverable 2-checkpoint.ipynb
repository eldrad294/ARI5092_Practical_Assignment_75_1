{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 2\n",
    "* Implement a linear chain CRF with a library\n",
    "* Use it on two data sets with the same set of features\n",
    "* Implement the model and evaluate with F-Score. How are the feature weights which are learnt different between the models?\n",
    "\n",
    "## File handling and data loading\n",
    "Loads data from files, for both POS training&testing and NER training&testing files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Notebook Imports\n",
    "\"\"\"\n",
    "import os\n",
    "import pycrfsuite # pip install python-crfsuite\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example: [[['In', 'IN'], ['an', 'DT'], ['Oct.', 'NNP'], ['19', 'CD'], ['review', 'NN'], ['of', 'IN'], ['``', '``'], ['The', 'DT'], ['Misanthrope', 'NN'], [\"''\", \"''\"], ['at', 'IN'], ['Chicago', 'NNP'], [\"'s\", 'POS'], ['Goodman', 'NNP'], ['Theatre', 'NNP'], ['(', '-LRB-'], ['``', '``'], ['Revitalized', 'VBN'], ['Classics', 'NNS'], ['Take', 'VBP'], ['the', 'DT'], ['Stage', 'NN'], ['in', 'IN'], ['Windy', 'NNP'], ['City', 'NNP'], [',', ','], [\"''\", \"''\"], ['Leisure', 'NN'], ['&', 'CC'], ['Arts', 'NNS'], [')', '-RRB-'], [',', ','], ['the', 'DT'], ['role', 'NN'], ['of', 'IN'], ['Celimene', 'NNP'], [',', ','], ['played', 'VBN'], ['by', 'IN'], ['Kim', 'NNP'], ['Cattrall', 'NNP'], [',', ','], ['was', 'VBD'], ['mistakenly', 'RB'], ['attributed', 'VBN'], ['to', 'IN'], ['Christina', 'NNP'], ['Haag', 'NNP'], ['.', '.']], [['Ms.', 'NNP'], ['Haag', 'NNP'], ['plays', 'VBZ'], ['Elianti', 'NNP'], ['.', '.']], [['Rolls', 'NNP'], ['-', 'HYPH'], ['Royce', 'NNP'], ['Motor', 'NNP'], ['Cars', 'NNPS'], ['Inc.', 'NNP'], ['said', 'VBD'], ['it', 'PRP'], ['expects', 'VBZ'], ['its', 'PRP$'], ['U.S.', 'NNP'], ['sales', 'NNS'], ['to', 'TO'], ['remain', 'VB'], ['steady', 'JJ'], ['at', 'IN'], ['about', 'IN'], ['1,200', 'CD'], ['cars', 'NNS'], ['in', 'IN'], ['1990', 'CD'], ['.', '.']], [['The', 'DT'], ['luxury', 'NN'], ['auto', 'NN'], ['maker', 'NN'], ['last', 'JJ'], ['year', 'NN'], ['sold', 'VBD'], ['1,214', 'CD'], ['cars', 'NNS'], ['in', 'IN'], ['the', 'DT'], ['U.S.', 'NNP']], [['Howard', 'NNP'], ['Mosher', 'NNP'], [',', ','], ['president', 'NN'], ['and', 'CC'], ['chief', 'JJ'], ['executive', 'NN'], ['officer', 'NN'], [',', ','], ['said', 'VBD'], ['he', 'PRP'], ['anticipates', 'VBZ'], ['growth', 'NN'], ['for', 'IN'], ['the', 'DT'], ['luxury', 'NN'], ['auto', 'NN'], ['maker', 'NN'], ['in', 'IN'], ['Britain', 'NNP'], ['and', 'CC'], ['Europe', 'NNP'], [',', ','], ['and', 'CC'], ['in', 'IN'], ['Far', 'JJ'], ['Eastern', 'JJ'], ['markets', 'NNS'], ['.', '.']]]\n",
      "------------------------------------\n",
      "Example: [[['Measuring', 'NN'], ['cups', 'NNS'], ['may', 'MD'], ['soon', 'RB'], ['be', 'VB'], ['replaced', 'VBN'], ['by', 'IN'], ['tablespoons', 'NNS'], ['in', 'IN'], ['the', 'DT'], ['laundry', 'NN'], ['room', 'NN'], ['.', '.']], [['Procter', 'NNP'], ['&', 'CC'], ['Gamble', 'NNP'], ['Co.', 'NNP'], ['plans', 'VBZ'], ['to', 'TO'], ['begin', 'VB'], ['testing', 'VBG'], ['next', 'JJ'], ['month', 'NN'], ['a', 'DT'], ['superconcentrated', 'JJ'], ['detergent', 'NN'], ['that', 'WDT'], ['will', 'MD'], ['require', 'VB'], ['only', 'RB'], ['a', 'DT'], ['few', 'JJ'], ['spoonfuls', 'NNS'], ['per', 'IN'], ['washload', 'NN'], ['.', '.']], [['The', 'DT'], ['move', 'NN'], ['stems', 'VBZ'], ['from', 'IN'], ['lessons', 'NNS'], ['learned', 'VBN'], ['in', 'IN'], ['Japan', 'NNP'], ['where', 'WRB'], ['local', 'JJ'], ['competitors', 'NNS'], ['have', 'VBP'], ['had', 'VBD'], ['phenomenal', 'JJ'], ['success', 'NN'], ['with', 'IN'], ['concentrated', 'JJ'], ['soapsuds', 'NNS'], ['.', '.']], [['It', 'PRP'], ['also', 'RB'], ['marks', 'VBZ'], ['P&G', 'NNP'], [\"'s\", 'POS'], ['growing', 'VBG'], ['concern', 'NN'], ['that', 'IN'], ['its', 'PRP$'], ['Japanese', 'JJ'], ['rivals', 'NNS'], [',', ','], ['such', 'JJ'], ['as', 'IN'], ['Kao', 'NNP'], ['Corp.', 'NNP'], [',', ','], ['may', 'MD'], ['bring', 'VB'], ['their', 'PRP$'], ['superconcentrates', 'NNS'], ['to', 'IN'], ['the', 'DT'], ['U.S.', 'NNP'], ['.', '.']], [['The', 'DT'], ['Cincinnati', 'NNP'], ['consumer', 'NN'], ['-', 'HYPH'], ['products', 'NNS'], ['giant', 'NN'], ['got', 'VBD'], ['clobbered', 'VBN'], ['two', 'CD'], ['years', 'NNS'], ['ago', 'RB'], ['in', 'IN'], ['Japan', 'NNP'], ['when', 'WRB'], ['Kao', 'NNP'], ['introduced', 'VBD'], ['a', 'DT'], ['powerful', 'JJ'], ['detergent', 'NN'], [',', ','], ['called', 'VBN'], ['Attack', 'NNP'], [',', ','], ['which', 'WDT'], ['quickly', 'RB'], ['won', 'VBD'], ['a', 'DT'], ['30', 'CD'], ['%', 'NN'], ['stake', 'NN'], ['in', 'IN'], ['the', 'DT'], ['Japanese', 'JJ'], ['markets', 'NNS'], ['.', '.']]]\n",
      "------------------------------------\n",
      "Example: [[['-DOCSTART-', 'O']], [['EU', 'B-ORG'], ['rejects', 'O'], ['German', 'B-MISC'], ['call', 'O'], ['to', 'O'], ['boycott', 'O'], ['British', 'B-MISC'], ['lamb', 'O'], ['.', 'O']], [['Peter', 'B-PER'], ['Blackburn', 'I-PER']], [['BRUSSELS', 'B-LOC'], ['1996-08-22', 'O']], [['The', 'O'], ['European', 'B-ORG'], ['Commission', 'I-ORG'], ['said', 'O'], ['on', 'O'], ['Thursday', 'O'], ['it', 'O'], ['disagreed', 'O'], ['with', 'O'], ['German', 'B-MISC'], ['advice', 'O'], ['to', 'O'], ['consumers', 'O'], ['to', 'O'], ['shun', 'O'], ['British', 'B-MISC'], ['lamb', 'O'], ['until', 'O'], ['scientists', 'O'], ['determine', 'O'], ['whether', 'O'], ['mad', 'O'], ['cow', 'O'], ['disease', 'O'], ['can', 'O'], ['be', 'O'], ['transmitted', 'O'], ['to', 'O'], ['sheep', 'O'], ['.', 'O']]]\n",
      "------------------------------------\n",
      "Example: [[['-DOCSTART-', 'O']], [['SOCCER', 'O'], ['-', 'O'], ['JAPAN', 'B-LOC'], ['GET', 'O'], ['LUCKY', 'O'], ['WIN', 'O'], [',', 'O'], ['CHINA', 'B-PER'], ['IN', 'O'], ['SURPRISE', 'O'], ['DEFEAT', 'O'], ['.', 'O']], [['Nadim', 'B-PER'], ['Ladki', 'I-PER']], [['AL-AIN', 'B-LOC'], [',', 'O'], ['United', 'B-LOC'], ['Arab', 'I-LOC'], ['Emirates', 'I-LOC'], ['1996-12-06', 'O']], [['Japan', 'B-LOC'], ['began', 'O'], ['the', 'O'], ['defence', 'O'], ['of', 'O'], ['their', 'O'], ['Asian', 'B-MISC'], ['Cup', 'I-MISC'], ['title', 'O'], ['with', 'O'], ['a', 'O'], ['lucky', 'O'], ['2-1', 'O'], ['win', 'O'], ['against', 'O'], ['Syria', 'B-LOC'], ['in', 'O'], ['a', 'O'], ['Group', 'O'], ['C', 'O'], ['championship', 'O'], ['match', 'O'], ['on', 'O'], ['Friday', 'O'], ['.', 'O']]]\n"
     ]
    }
   ],
   "source": [
    "class DataLoader:\n",
    "    \"\"\"\n",
    "    Loads input data files and cleans up data into following format:\n",
    "    \n",
    "    eg: (Data1, Type1)\n",
    "    \"\"\"\n",
    "    #\n",
    "    def __init__(self, POS_train_path, POS_test_path, NER_train_path, NER_test_path):\n",
    "        \"\"\"\n",
    "        Loads data files into memory\n",
    "        \"\"\"\n",
    "        __POS_train_path = POS_train_path\n",
    "        __POS_test_path = POS_test_path\n",
    "        __NER_train_path = NER_train_path\n",
    "        __NER_test_path = NER_test_path\n",
    "        #\n",
    "        # Loads data from disk into memory\n",
    "        __POS_train_data, __POS_test_data, __NER_train_data, __NER_test_data = self.__extract_data_from_files(POS_train_path=__POS_train_path,\n",
    "                                                                                                              POS_test_path=__POS_test_path,\n",
    "                                                                                                              NER_train_path=__NER_train_path,\n",
    "                                                                                                              NER_test_path=__NER_test_path)\n",
    "        #\n",
    "        # Formats data currently loaded in memory into a formatted structure\n",
    "        self.__POS_train_structured_data, self.__POS_test_structured_data, self.__NER_train_structured_data,self.__NER_test_structured_data=self.__format_data(POS_train_data=__POS_train_data,\n",
    "                                                                                                                                                               POS_test_data=__POS_test_data,\n",
    "                                                                                                                                                               NER_train_data=__NER_train_data,\n",
    "                                                                                                                                                               NER_test_data=__NER_test_data)\n",
    "    #\n",
    "    def __extract_data_from_files(self, POS_train_path, POS_test_path, NER_train_path, NER_test_path):\n",
    "        \"\"\"\n",
    "        Opens data files and returns data in memory\n",
    "        \"\"\"\n",
    "        #\n",
    "        BASE_DIR = os.path.join( os.path.dirname(os.getcwd()))\n",
    "        #\n",
    "        with open(BASE_DIR + POS_train_path) as f:\n",
    "            POS_train_data = f.read()\n",
    "        with open(BASE_DIR + POS_test_path) as f:\n",
    "            POS_test_data = f.read()\n",
    "        with open(BASE_DIR + NER_train_path) as f:\n",
    "            NER_train_data = f.read()\n",
    "        with open(BASE_DIR + NER_test_path) as f:\n",
    "            NER_test_data = f.read()\n",
    "        #\n",
    "        return POS_train_data, POS_test_data, NER_train_data, NER_test_data\n",
    "    #\n",
    "    def __format_data(self, POS_train_data, POS_test_data, NER_train_data, NER_test_data):\n",
    "        \"\"\"\n",
    "        Formats data into a python data structure (list of lists)\n",
    "        eg: (Data1, Type1)\n",
    "        \"\"\"\n",
    "        POS_train_structured_data, POS_test_structured_data, NER_train_structured_data, NER_test_structured_data = [],[],[],[]\n",
    "        temp_list=[]\n",
    "        for line in POS_train_data.split(\"\\n\"):\n",
    "            if line is not None and line != \"\": \n",
    "                sub_list = line.split(\"\\t\")\n",
    "                temp_list.append(sub_list)\n",
    "            else:\n",
    "                POS_train_structured_data.append(temp_list)\n",
    "                temp_list = []\n",
    "        temp_list = []\n",
    "        for line in POS_test_data.split(\"\\n\"):\n",
    "            if line is not None and line != \"\": \n",
    "                sub_list = line.split(\"\\t\")\n",
    "                temp_list.append(sub_list)\n",
    "            else:\n",
    "                POS_test_structured_data.append(temp_list)\n",
    "                temp_list = []\n",
    "        temp_list = []\n",
    "        for line in NER_train_data.split(\"\\n\"):\n",
    "            if line is not None and line != \"\": \n",
    "                sub_list = line.split(\"\\t|\")\n",
    "                temp_list.append(sub_list)\n",
    "            else:\n",
    "                NER_train_structured_data.append(temp_list)\n",
    "                temp_list = []\n",
    "        #\n",
    "        temp_list = []\n",
    "        for line in NER_test_data.split(\"\\n\"):\n",
    "            if line is not None and line != \"\": \n",
    "                sub_list = line.split(\"\\t|\")\n",
    "                temp_list.append(sub_list)\n",
    "            else:\n",
    "                NER_test_structured_data.append(temp_list)\n",
    "                temp_list = []\n",
    "        #\n",
    "        return POS_train_structured_data, POS_test_structured_data, NER_train_structured_data, NER_test_structured_data\n",
    "    #\n",
    "    def load_data(self):\n",
    "        \"\"\"\n",
    "        Method wrapper which loads data into memory and returns all relevant training and testing files\n",
    "        \"\"\"\n",
    "        return self.__POS_train_structured_data, self.__POS_test_structured_data, self.__NER_train_structured_data, self.__NER_test_structured_data\n",
    "#\n",
    "data_loader_obj = DataLoader(POS_train_path=\"\\\\data\\\\pos\\\\train.col\",\n",
    "                             POS_test_path=\"\\\\data\\\\pos\\\\test.col\",\n",
    "                             NER_train_path=\"\\\\data\\\\ner-pol\\\\train.iob\",\n",
    "                             NER_test_path=\"\\\\data\\\\ner-pol\\\\test.iob\")\n",
    "POS_train_data, POS_test_data, NER_train_data, NER_test_data = data_loader_obj.load_data()\n",
    "print(\"Example: \" + str(POS_train_data[0:5]))\n",
    "print(\"------------------------------------\")\n",
    "print(\"Example: \" + str(POS_test_data[0:5]))\n",
    "print(\"------------------------------------\")\n",
    "print(\"Example: \" + str(NER_train_data[0:5]))\n",
    "print(\"------------------------------------\")\n",
    "print(\"Example: \" + str(NER_test_data[0:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Enhancer\n",
    "\n",
    "Adds more features to the already loaded vectors, including the following features:\n",
    "\n",
    "* The word itself, coverted to lower case\n",
    "* Word Suffix (-2,-3)\n",
    "* Boolean if string is uppercased\n",
    "* Boolean if string is a title (eg: Title)\n",
    "* Boolean if string is a digit\n",
    "* The postag\n",
    "* The string before it, converted to lowercase\n",
    "* Boolean if the string before it is a title (eg: Title)\n",
    "* Boolean if the string before it is uppercased\n",
    "* Boolean if the string before it is a digit\n",
    "* postag of string before it\n",
    "* The string after it, converted to lowercase\n",
    "* Boolean if the string after it is a title (eg: Title)\n",
    "* Boolean if the string after it is uppercased\n",
    "* Boolean if the string after it is a digit\n",
    "* postag of string after it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['In', 'IN'], ['an', 'DT'], ['Oct.', 'NNP'], ['19', 'CD'], ['review', 'NN'], ['of', 'IN'], ['``', '``'], ['The', 'DT'], ['Misanthrope', 'NN'], [\"''\", \"''\"], ['at', 'IN'], ['Chicago', 'NNP'], [\"'s\", 'POS'], ['Goodman', 'NNP'], ['Theatre', 'NNP'], ['(', '-LRB-'], ['``', '``'], ['Revitalized', 'VBN'], ['Classics', 'NNS'], ['Take', 'VBP'], ['the', 'DT'], ['Stage', 'NN'], ['in', 'IN'], ['Windy', 'NNP'], ['City', 'NNP'], [',', ','], [\"''\", \"''\"], ['Leisure', 'NN'], ['&', 'CC'], ['Arts', 'NNS'], [')', '-RRB-'], [',', ','], ['the', 'DT'], ['role', 'NN'], ['of', 'IN'], ['Celimene', 'NNP'], [',', ','], ['played', 'VBN'], ['by', 'IN'], ['Kim', 'NNP'], ['Cattrall', 'NNP'], [',', ','], ['was', 'VBD'], ['mistakenly', 'RB'], ['attributed', 'VBN'], ['to', 'IN'], ['Christina', 'NNP'], ['Haag', 'NNP'], ['.', '.']], [['Ms.', 'NNP'], ['Haag', 'NNP'], ['plays', 'VBZ'], ['Elianti', 'NNP'], ['.', '.']], [['Rolls', 'NNP'], ['-', 'HYPH'], ['Royce', 'NNP'], ['Motor', 'NNP'], ['Cars', 'NNPS'], ['Inc.', 'NNP'], ['said', 'VBD'], ['it', 'PRP'], ['expects', 'VBZ'], ['its', 'PRP$'], ['U.S.', 'NNP'], ['sales', 'NNS'], ['to', 'TO'], ['remain', 'VB'], ['steady', 'JJ'], ['at', 'IN'], ['about', 'IN'], ['1,200', 'CD'], ['cars', 'NNS'], ['in', 'IN'], ['1990', 'CD'], ['.', '.']], [['The', 'DT'], ['luxury', 'NN'], ['auto', 'NN'], ['maker', 'NN'], ['last', 'JJ'], ['year', 'NN'], ['sold', 'VBD'], ['1,214', 'CD'], ['cars', 'NNS'], ['in', 'IN'], ['the', 'DT'], ['U.S.', 'NNP']], [['Howard', 'NNP'], ['Mosher', 'NNP'], [',', ','], ['president', 'NN'], ['and', 'CC'], ['chief', 'JJ'], ['executive', 'NN'], ['officer', 'NN'], [',', ','], ['said', 'VBD'], ['he', 'PRP'], ['anticipates', 'VBZ'], ['growth', 'NN'], ['for', 'IN'], ['the', 'DT'], ['luxury', 'NN'], ['auto', 'NN'], ['maker', 'NN'], ['in', 'IN'], ['Britain', 'NNP'], ['and', 'CC'], ['Europe', 'NNP'], [',', ','], ['and', 'CC'], ['in', 'IN'], ['Far', 'JJ'], ['Eastern', 'JJ'], ['markets', 'NNS'], ['.', '.']]]\n",
      "[[['-DOCSTART-', 'O']], [['EU', 'B-ORG'], ['rejects', 'O'], ['German', 'B-MISC'], ['call', 'O'], ['to', 'O'], ['boycott', 'O'], ['British', 'B-MISC'], ['lamb', 'O'], ['.', 'O']], [['Peter', 'B-PER'], ['Blackburn', 'I-PER']], [['BRUSSELS', 'B-LOC'], ['1996-08-22', 'O']], [['The', 'O'], ['European', 'B-ORG'], ['Commission', 'I-ORG'], ['said', 'O'], ['on', 'O'], ['Thursday', 'O'], ['it', 'O'], ['disagreed', 'O'], ['with', 'O'], ['German', 'B-MISC'], ['advice', 'O'], ['to', 'O'], ['consumers', 'O'], ['to', 'O'], ['shun', 'O'], ['British', 'B-MISC'], ['lamb', 'O'], ['until', 'O'], ['scientists', 'O'], ['determine', 'O'], ['whether', 'O'], ['mad', 'O'], ['cow', 'O'], ['disease', 'O'], ['can', 'O'], ['be', 'O'], ['transmitted', 'O'], ['to', 'O'], ['sheep', 'O'], ['.', 'O']]]\n",
      "------------------------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Postword' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-33f2688a6fe2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNER_train_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"------------------------------------\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m \u001b[0mX_POS_train_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mPOS_train_data\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m \u001b[0my_POS_train_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mget_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mPOS_train_data\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[0mX_NER_train_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mNER_train_data\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-33f2688a6fe2>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNER_train_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"------------------------------------\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m \u001b[0mX_POS_train_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mPOS_train_data\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m \u001b[0my_POS_train_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mget_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mPOS_train_data\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[0mX_NER_train_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mNER_train_data\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-33f2688a6fe2>\u001b[0m in \u001b[0;36mextract_features\u001b[1;34m(doc, model_type)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;31m# A function for extracting features in documents\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mword2features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;31m# A function for generating the list of labels for each document\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-33f2688a6fe2>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;31m# A function for extracting features in documents\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mword2features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;31m# A function for generating the list of labels for each document\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-33f2688a6fe2>\u001b[0m in \u001b[0;36mword2features\u001b[1;34m(doc, i, model_type)\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'BOS'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[0mPostword\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[0mword1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Postword' is not defined"
     ]
    }
   ],
   "source": [
    "def word2features(doc, i, model_type):\n",
    "    \"\"\"\n",
    "    Accepts a word, and respective POS tag, and converts it into a vector of features\n",
    "    \n",
    "    Applies different features to the model, depending on whether we are tackling POS tagging, or NER tagging.\n",
    "    \"\"\"\n",
    "    #print(doc[i])\n",
    "    word = doc[i][0]\n",
    "    postag = doc[i][1]\n",
    "    #\n",
    "    if model_type == 0: # POS Tagging Features\n",
    "        #\n",
    "        features = [\n",
    "            'bias',\n",
    "            'word.lower=' + word.lower(),\n",
    "            'word[-3:]=' + word[-3:],\n",
    "            'word[-2:]=' + word[-2:],\n",
    "            'word.isupper=%s' % word.isupper(),\n",
    "            'word.istitle=%s' % word.istitle(),\n",
    "            'word.isdigit=%s' % word.isdigit(),\n",
    "            'postag=' + postag\n",
    "        ]\n",
    "        #\n",
    "        # Preword\n",
    "        if i > 0:\n",
    "            word1 = doc[i-1][0]\n",
    "            postag1 = doc[i-1][1]\n",
    "            features.extend([\n",
    "                '-1:word.lower=' + word1.lower(),\n",
    "                '-1:word.istitle=%s' % word1.istitle(),\n",
    "                '-1:word.isupper=%s' % word1.isupper(),\n",
    "                '-1:word.isdigit=%s' % word1.isdigit(),\n",
    "                '-1:postag=' + postag1\n",
    "            ])\n",
    "        else:\n",
    "            # Beginning of document\n",
    "            features.append('BOS')\n",
    "        # \n",
    "        # Postword\n",
    "        if i < len(doc)-1:\n",
    "            word1 = doc[i+1][0]\n",
    "            postag1 = doc[i+1][1]\n",
    "            features.extend([\n",
    "                '+1:word.lower=' + word1.lower(),\n",
    "                '+1:word.istitle=%s' % word1.istitle(),\n",
    "                '+1:word.isupper=%s' % word1.isupper(),\n",
    "                '+1:word.isdigit=%s' % word1.isdigit(),\n",
    "                '+1:postag=' + postag1\n",
    "            ])\n",
    "        else:\n",
    "            # End of document\n",
    "            features.append('EOS')\n",
    "    else:\n",
    "        #\n",
    "        features = [\n",
    "            'bias',\n",
    "            'word.lower=' + word.lower(),\n",
    "            'word[-3:]=' + word[-3:],\n",
    "            'word[-2:]=' + word[-2:],\n",
    "            'word.isupper=%s' % word.isupper(),\n",
    "            'word.istitle=%s' % word.istitle(),\n",
    "            'word.isdigit=%s' % word.isdigit(),\n",
    "            'postag=' + postag\n",
    "        ]\n",
    "        #\n",
    "        # Preword\n",
    "        if i > 0:\n",
    "            word1 = doc[i-1][0]\n",
    "            postag1 = doc[i-1][1]\n",
    "            features.extend([\n",
    "                '-1:word.lower=' + word1.lower(),\n",
    "                '-1:word.istitle=%s' % word1.istitle(),\n",
    "                '-1:word.isupper=%s' % word1.isupper(),\n",
    "                '-1:word.isdigit=%s' % word1.isdigit(),\n",
    "                '-1:postag=' + postag1\n",
    "            ])\n",
    "        else:\n",
    "            # Beginning of document\n",
    "            features.append('BOS')\n",
    "        #\n",
    "        # Postword\n",
    "        if i < len(doc)-1:\n",
    "            word1 = doc[i+1][0]\n",
    "            postag1 = doc[i+1][1]\n",
    "            features.extend([\n",
    "                '+1:word.lower=' + word1.lower(),\n",
    "                '+1:word.istitle=%s' % word1.istitle(),\n",
    "                '+1:word.isupper=%s' % word1.isupper(),\n",
    "                '+1:word.isdigit=%s' % word1.isdigit(),\n",
    "                '+1:postag=' + postag1\n",
    "            ])\n",
    "        else:\n",
    "            # End of document\n",
    "            features.append('EOS')\n",
    "    #    \n",
    "    return features\n",
    "#\n",
    "# A function for extracting features in documents\n",
    "def extract_features(doc, model_type):\n",
    "    return [word2features(doc, i, model_type) for i in range(len(doc))]\n",
    "#\n",
    "# A function for generating the list of labels for each document\n",
    "def get_labels(doc):\n",
    "    return [label for (token, label) in doc]\n",
    "#\n",
    "# A function for generating the list of features for each document\n",
    "def get_features(doc):\n",
    "    return [token for (token, label) in doc]\n",
    "#\n",
    "print(POS_train_data[:5])\n",
    "print(NER_train_data[:5])\n",
    "print(\"------------------------------------\")\n",
    "X_POS_train_data = [extract_features(doc, 0) for doc in POS_train_data]\n",
    "y_POS_train_data = [get_labels(doc) for doc in POS_train_data]\n",
    "X_NER_train_data = [extract_features(doc, 1) for doc in NER_train_data]\n",
    "y_NER_train_data = [get_labels(doc) for doc in NER_train_data]\n",
    "print(\"------------------------------------\")\n",
    "print(\"POS Train Data Snippet:\")\n",
    "print(X_POS_train_data[:5])\n",
    "print(y_POS_train_data[:5])\n",
    "print(\"------------------------------------\")\n",
    "print(\"NER Train Data Snippet:\")\n",
    "print(X_NER_train_data[:5])\n",
    "print(y_NER_train_data[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model - POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"POS_crf.model\"\n",
    "file_exists = os.path.exists(file_path)\n",
    "if(not file_exists):\n",
    "    trainer_POS = pycrfsuite.Trainer(verbose=True)\n",
    "    #\n",
    "    # Submit training data to the trainer\n",
    "    print('Submitting POS dataset..')\n",
    "    for xseq, yseq in zip(X_POS_train_data, y_POS_train_data):\n",
    "        trainer_POS.append(xseq,yseq)\n",
    "    #\n",
    "    # Set the parameters of the model\n",
    "    trainer_POS.set_params({\n",
    "        # coefficient for L1 penalty\n",
    "        'c1': 0.1,\n",
    "\n",
    "        # coefficient for L2 penalty\n",
    "        'c2': 0.01,  \n",
    "\n",
    "        # maximum number of iterations\n",
    "        'max_iterations': 50,\n",
    "\n",
    "        # whether to include transitions that\n",
    "        # are possible, but not observed\n",
    "        'feature.possible_transitions': True\n",
    "    })\n",
    "    #\n",
    "    # Provide a file name as a parameter to the train function, such that\n",
    "    # the model will be saved to the file when training is finished\n",
    "    print('Training POS dataset..')\n",
    "    trainer_POS.train(file_path)\n",
    "    print('POS Model Trained..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model - NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"NER_crf.model\"\n",
    "file_exists = os.path.exists(file_path)\n",
    "if(not file_exists):\n",
    "    trainer_NER = pycrfsuite.Trainer(verbose=True)\n",
    "    #\n",
    "    # Submit training data to the trainer\n",
    "    print('Submitting NER dataset..')\n",
    "    for xseq, yseq in zip(X_NER_train_data, y_NER_train_data):\n",
    "        trainer_NER.append(xseq, yseq)\n",
    "    #\n",
    "    # Set the parameters of the model\n",
    "    trainer_NER.set_params({\n",
    "        # coefficient for L1 penalty\n",
    "        'c1': 0.1,\n",
    "\n",
    "        # coefficient for L2 penalty\n",
    "        'c2': 0.01,  \n",
    "\n",
    "        # maximum number of iterations\n",
    "        'max_iterations': 50,\n",
    "\n",
    "        # whether to include transitions that\n",
    "        # are possible, but not observed\n",
    "        'feature.possible_transitions': True\n",
    "    })\n",
    "    #\n",
    "    # Provide a file name as a parameter to the train function, such that\n",
    "    # the model will be saved to the file when training is finished   \n",
    "    print('Training NER dataset..')\n",
    "    trainer_NER.train(file_path)\n",
    "    print('NER Model Trained..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running models on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_POS_test_data = [extract_features(doc, 0) for doc in POS_test_data]\n",
    "y_POS_test_data = [get_labels(doc) for doc in POS_test_data]\n",
    "X_NER_test_data = [extract_features(doc, 1) for doc in NER_test_data]\n",
    "y_NER_test_data = [get_labels(doc) for doc in NER_test_data]\n",
    "print(\"POS Train Data Snippet:\")\n",
    "print(X_POS_test_data[:5])\n",
    "print(y_POS_test_data[:5])\n",
    "print(\"NER Train Data Snippet:\")\n",
    "print(X_NER_test_data[:5])\n",
    "print(y_NER_test_data[:5])\n",
    "print(\"--------------------\")\n",
    "#\n",
    "# Running test data on POS model   \n",
    "tagger_POS = pycrfsuite.Tagger()\n",
    "tagger_POS.open('POS_crf.model')\n",
    "y_POS_pred = [tagger_POS.tag(xseq) for xseq in X_POS_test_data]\n",
    "#\n",
    "# Running test data on NER model   \n",
    "tagger_NER = pycrfsuite.Tagger()\n",
    "tagger_NER.open('NER_crf.model')\n",
    "y_NER_pred = [tagger_NER.tag(xseq) for xseq in X_NER_test_data]\n",
    "#\n",
    "print(\"POS Pred Data Snippet:\")\n",
    "print(y_POS_pred[:5])\n",
    "print(\"--------------------\")\n",
    "print(\"NER Pred Data Snippet:\")\n",
    "print(y_NER_pred[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average='weighted'\n",
    "#\n",
    "# Flatten Lists\n",
    "y_POS_test_data_flat, y_POS_pred_flat, y_NER_test_data_flat, y_NER_pred_flat = [],[],[],[]\n",
    "for sub_list in y_POS_test_data:\n",
    "    for item in sub_list:\n",
    "        y_POS_test_data_flat.append(item)\n",
    "for sub_list in y_POS_pred:\n",
    "    for item in sub_list:\n",
    "        y_POS_pred_flat.append(item)\n",
    "for sub_list in y_NER_test_data:\n",
    "    for item in sub_list:\n",
    "        y_NER_test_data_flat.append(item)\n",
    "for sub_list in y_NER_pred:\n",
    "    for item in sub_list:\n",
    "        y_NER_pred_flat.append(item)\n",
    "print(y_POS_test_data_flat[:30])\n",
    "print(y_POS_pred_flat[:30])\n",
    "print(y_NER_test_data_flat[:30])\n",
    "print(y_NER_pred_flat[:30])\n",
    "#\n",
    "# POS Evaluation\n",
    "accuracy = accuracy_score(y_POS_test_data_flat, y_POS_pred_flat)\n",
    "precision = precision_score(y_POS_test_data_flat, y_POS_pred_flat, average=average)\n",
    "recall = recall_score(y_POS_test_data_flat, y_POS_pred_flat, average=average)\n",
    "f1_s = f1_score(y_POS_test_data_flat, y_POS_pred_flat, average=average) \n",
    "print(\"POS Accuracy: \" + str(accuracy))\n",
    "print(\"POS Precision: \" + str(precision))\n",
    "print(\"POS Recall: \" + str(recall))\n",
    "print(\"POS F1 Score: \" + str(f1_s) + \"\\n\")\n",
    "#\n",
    "# NER Evaluation\n",
    "accuracy = accuracy_score(y_NER_test_data_flat, y_NER_pred_flat)\n",
    "precision = precision_score(y_NER_test_data_flat, y_NER_pred_flat, average=average)\n",
    "recall = recall_score(y_NER_test_data_flat, y_NER_pred_flat, average=average)\n",
    "f1_s = f1_score(y_NER_test_data_flat, y_NER_pred_flat, average=average)\n",
    "print(\"NER Accuracy: \" + str(accuracy))\n",
    "print(\"NER Precision: \" + str(precision))\n",
    "print(\"NER Recall: \" + str(recall))\n",
    "print(\"NER F1 Score: \" + str(f1_s))\n",
    "#\n",
    "# Print out the classification report\n",
    "print(\"POS Classification Report\")\n",
    "print(classification_report(\n",
    "    y_POS_test_data_flat, y_POS_pred_flat,\n",
    "    target_names=[\"NN\", \"NNS\",\"MD\",\"RB\",\"VB\",\"VBN\",\"IN\",\"DT\",\"NNP\",\"VBZ\",\"TO\",\"VBG\",\"JJ\",\"WDT\"]))\n",
    "print(\"NER Classification Report\")\n",
    "print(classification_report(\n",
    "    y_NER_test_data_flat, y_NER_pred_flat,\n",
    "    target_names=[\"B-LOC\", \"O\",\"I-MISC\",\"I-LOC\",\"B-PER\",\"B-MISC\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
